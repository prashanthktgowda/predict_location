import pandas as pd
import numpy as np
import os
import re
import pickle
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Lasso
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

#Required NTKL
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')

data = pd.read_csv('dataset.csv', delimiter=',', on_bad_lines='skip')
data.dropna(inplace=True)
data['area_name'].fillna(data['city'], inplace=True)

# prompt: remove numericals from area_name
data['area_name'] = data['area_name'].apply(lambda x: re.sub(r'\d+', '', str(x)))
data["area_name"] = data["area_name"].str.replace("/","").replace("+","").replace("-"," ").replace("  "," ").replace("-nd","")
data['area_name'] = data['area_name'].str.lstrip()

punctuation_signs = list("?:!.,;")
wordnet_lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

data['area_name'] = data['area_name'].str.replace("\r", "").replace("\n", " ").replace("+", "").replace("/", " ").replace("    ", " ").replace('"', '').str.lower()
for punct_sign in punctuation_signs:
    data['area_name'] = data['area_name'].str.replace(punct_sign, '')
data['Full_Address'] = (data['area_name'] + " " + data['city'] + " " + data['state']).str.lower()

# Create new features from the address
data['address_length'] = data['Full_Address'].apply(lambda x: len(x.split()))
data['num_special_chars'] = data['Full_Address'].apply(lambda x: sum(not c.isalnum() for c in x))

# Example of other possible features
# Count the number of numeric characters
data['num_numeric'] = data['Full_Address'].apply(lambda x: sum(c.isdigit() for c in x))

X = data['Full_Address']  # Feature: Full address
y = data[['latitude', 'longitude']]  # Target: Latitude and Longitude

# Check if Full_Address column exists and is in the correct form
print(data['Full_Address'].tail())

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize the vectorizer
tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))

# Transform the address data into vector form
X_tfidf = tfidf_vectorizer.fit_transform(data['Full_Address'])

# prompt: print the shape of x and y

print(X_tfidf.shape)
print(y.shape)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Assuming 'y' is your target variable (latitude/longitude)
X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# Train Random Forest Model
rf_model = RandomForestRegressor(n_estimators=200, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Random Forest - Mean Absolute Error: {mae}")
print(f"Random Forest - Mean Squared Error: {mse}")
print(f"Random Forest - R-squared: {r2}")

